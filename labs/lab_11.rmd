---
title: "lab_11"
author: "Adelia McGuire"
date: "2024-11-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

-   Our usual libraries for working with data, including dates and column names, plus rvest.

## Load libraries and establish settings

**Task** Create a codeblock and load appropriate packages and settings for this lab.

```{r}
library(rvest)
library(tidyverse)
library(janitor)
library(lubridate)
library(dplyr)
library(stringr)
```

Let's get to scraping. We'll be working on collecting information about Maryland election results, and then we'll grab some congressional press releases. For Maryland races, we'll focus on Board of Education races using this CNS story as a guide: https://cnsmaryland.org/2024/11/08/md-conservatives-make-gains-in-school-board-races/. You should read it.

## Questions

**Q1**. Write code to scrape the table of unofficial results from Frederick County's Board of Education races (https://elections.maryland.gov/elections/2024/general_Results/gen_results_2024_by_county_11.html), producing a dataframe that contains the results of that race for each candidate and removing the total. You'll need to identify which table on the page contains the BOE results. All numbers should actually be numbers, including the percentage. Then make a bar chart of the results, noting that the top 3 candidates win.

**A1** As you will see in my bar chart below, the top 3 candidates of the Frederick County's BOE results are Colt Morningstar Black, Janie Monier, Jaimie Kiersten Brennan. These three leading candidates cna be differentiated in their green coloring. 

```{r}
fredrick_url <- "https://elections.maryland.gov/elections/2024/general_Results/gen_results_2024_by_county_11.html"

results <- fredrick_url |>
  read_html()

results
```

```{r}
results <- fredrick_url |>
  read_html() |>
  html_table()
  results <- results[[9]]

results
```

```{r}
results <- fredrick_url |>
  read_html() |>
  html_table()

results <- results[[9]] |>
  clean_names() |>
  slice(-9) |>
  mutate(early_voting = as.numeric(gsub(",","", early_voting))) |>
  mutate(election_day = as.numeric(gsub(",","", election_day))) |>
  mutate(mail_in_ballot = as.numeric(gsub(",","", mail_in_ballot))) |>
  mutate(total = as.numeric(gsub(",","", total))) |>
  mutate(percentage = as.numeric(gsub("%","", percentage)))

results
```

```{r}
results <- fredrick_url |>
  read_html() |>
  html_table()

results <- results[[9]] |>
  clean_names() |>
  slice(-9) |>
  mutate(
    early_voting = as.numeric(gsub(",", "", early_voting)),
    election_day = as.numeric(gsub(",", "", election_day)),
    mail_in_ballot = as.numeric(gsub(",", "", mail_in_ballot)),
    total = as.numeric(gsub(",", "", total)),
    percentage = as.numeric(gsub("%", "", percentage))
  )

top_3_candidates <- results|>
  arrange(desc(total)) |>
  slice(1:3)

ggplot(results, aes(x = reorder(name, total), y = total, fill = name %in% top_3_candidates$name)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Frederick County's Board of Education Election Results",
    x = "Candidate",
    y = "Total Votes",
    subtitle = "Top 3 Candidates: Colt Morningstar Black, Janie Monier, Jaimie Kiersten Brennan"
  ) +
  scale_fill_manual(values = c("navy", "green")) +  
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


**Q2** Next, let's scrape the list of press releases from Maryland's Office of the Public Defender, <https://osp.maryland.gov/category/press-releases/>. This isn't a table, so you'll need to use `html_elements()` and your browser's inspector and do some clean up on the results. The result should be a dataframe with three columns: title, url and date. HINT: you can extract the date from the title using lubridate OR you can use the `separate` function.

You should have 10 releases when finished, not 20.

Then, write code that finds the most recent release with the word "Campaign" in the title. What election does it refer to?

**A2** According to my codeblock (located in lines 115 to 118), the most recent and only press release that contains the word "Campaign" was published on April 3rd, 2024 (my birthday!) and is titled, "April 3, 2024: John King for Governor Campaign Cited for Authority Line Violations". This specific press release published on April 3rd refers to the 2022 Maryland Gubernatorial Primary Election. In my readings of this release I found that it mentions campaign activities and events related to the 2022 Maryland Primary Election. 

```{r}
press_release_url <- "https://osp.maryland.gov/category/press-releases/"
```

```{r}
press_release_results <- press_release_url |>
  read_html()

press_release_results
```

```{r}
press_release_results |> html_elements('article') 
```

```{r}
press_release_results |> html_elements('article') |> html_text()
```

```{r}
press_releases <- press_release_results |> html_elements("article a")

press_releases_with_urls <- tibble(
  title = press_releases |> html_text(trim = TRUE),
  url = press_releases |> html_attr("href"),
)
```

```{r}
press_releases_with_urls <- press_releases_with_urls |>
  filter(!title=="Read the Rest…") |>
  mutate(
  date = mdy(title)
  )

```

```{r}
contains_campaign <- press_releases_with_urls |>
  filter(str_detect(title,"Campaign"))
```

**Q3** Sen. Ben Cardin, D-Maryland, has posted hundreds of press releases at <https://www.cardin.senate.gov/?post_type=press-releases>. It would be great to have all of them in a dataframe that has the following columns: date, title and url.

To do this, you will need to scrape the page's html and save that to a variable, and *then* extract the dates, titles and urls into *separate* dataframes using html_elements(). We turn a list into a dataframe using `as_tibble()`.

At the end, you'll have three dataframes that you want to combine into a single dataframe. When we want to combine the rows of identical dataframes, we used `bind_rows()`. If you were combining columns instead of rows, there's a similar function. Use it to put all of the dataframes together into a single one. You are combining columns, not rows.

When you're done, rename the columns so they make sense, then make sure the date column is an actual date.

Finally, tell me what questions you could ask of this data, and what other information about it would be useful to have. Be creative.

**A3** As stated in the question, Senator Ben Cardin has hundreds or press releases which means there are numerous questions that could be posed of the data which they contain. Through my work with this dataframe and my general analysis of the titles, urls, and dates of the press releases which it contains, I have narrowed down two creative questions that I feel would reveal interesting information about this data. The first question and the broader of the two is... Which topics are most frequently addressed and discussed in Senator Ben Cardin’s press releases, and how do these topics change and evolve over time? The second question and the more detailed of the two is... How does the distribution of Senator Ben Cardin's press releases vary over time and what specific patterns can be identified surrounding key political periods such as legislative sessions, election years, national crises, and policy debates? While, as I said, there are seemingly endless questions that you could delve into regarding this high quanity of press releases and the data they contain, these question are two which I found particular interest in. 

```{r}

cardin_senate_url <- "https://www.cardin.senate.gov/?post_type=press-releases"
cardin_senate_press_release <- read_html(cardin_senate_url)

cardin_press_releases <- cardin_senate_press_release |> html_elements("article a")

titles <- cardin_press_releases |> html_text(trim = TRUE)
urls <- cardin_press_releases |> html_attr("href")

dates <- cardin_senate_press_release |> 
  html_elements("article h5.customBlog_item__date") |> 
  html_text(trim = TRUE)

if (length(dates) < length(titles)) {
  dates <- c(dates, rep(NA, length(titles) - length(dates))) 
}

cardin_press_releases_with_urls <- tibble(
  title_of_press_release = titles,  
  url_of_press_release = urls,      
  publication_date_of_press_release = dates    
)

cardin_press_releases_with_urls <- cardin_press_releases_with_urls |>
  filter(title_of_press_release != "Read More")

cardin_press_releases_with_urls <- cardin_press_releases_with_urls |>
  mutate(
    publication_date_of_press_release = mdy(publication_date_of_press_release)  
  )

cardin_press_releases_with_urls
```
