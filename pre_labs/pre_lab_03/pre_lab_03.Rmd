---
title: "pre_lab_03.Rmd"
author: "Adelia McGuire"
date: "2024-09-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
```

## About this notebook

This notebook contains code and explanatory text that your should review and run as you read through two chapters on data cleaning from the course textbook, "Data Journalism with R and the Tidyverse". Answer questions and edit the document as directed.

Running this notebook will help you understand key data analysis methods and concepts that you will put into practice during this week's lab.

When you are finished running the code in this notebook, you will push changes to your course GitHub repo, and upload the link to ELMS as instructed.

## Data Cleaning, Part I

### Task 1: Load libraries and settings

**Task** Run the following code in the gray-colored codeblock below to load the tidyverse library and turn off scientific notation.

```{r}
# Remove scientific notation
options(scipen=999)
# Load the tidyverse   
library(tidyverse)
```

### Task 2: Load data

**Task** Load some precinct-level election results data from Texas for the 2020 general election by running the following code. We'll use the guess_max() function as an argument to use the first 10 rows to set the data type. What does the first line of the red Warning message that prints out when you load the data say? Answer below. 

**Answer**
The first line of the red warning message says, "One or more parsing issues, call `problems()` on your data frame for details, e.g" This warning includes a section called column specification that states the specifics of the location of the problem as well as the delimiter. 

```{r}
texas_precinct_20 <- read_csv("data/tx_precinct_2020.csv", guess_max=10)
```

### Task 3: Check for problems on load

**Task** Check for problems that occurred when loading the Texas precinct results by running the following code. How many problems were there, as shown by the number of rows in the output table showing errors? What do you think the problem is that R is describing? Answer below. 

**Answer** According to what is reflected in the data, there are 1,640 rows in the output table showing errors. I believe that the problem that R is describing is that there are numerical values showing under the "actual" column whcih is defined as a character column. This would be a problem because their should not be numerical values under a character column. 

```{r}

problems(texas_precinct_20)

```

### Task 4: Reload data

**Task** Run the following codeblock to reload the data, using every row to set the data types. Does it show any parsing errors when you run? Answer below 

**Answer** Through using the problem() function, the issue I identified within the Texas precinct results lies at columns 12 and 13. I believe that R is describing the problem that is both of these columns are character columns but are showing numbers. 

```{r}
texas_precinct_20 <- read_csv("data/tx_precinct_2020.csv", guess_max=476915)
```

### Task 5: Examine the data with glimpse

**Task** Run the following codeblock to glimpse the data. What data type is the "district" field? What data type is the "precinct" field? What data type is the "mail" column? Answer below. 

**Answer** The "district" field is a <dbl> or numeric data type and the "precinct" field is a <chr> or character data type. The "mail" column is numeric data type. Things that should be characters are labeled as <chr> and things that should be numbers are labled as <dbl>. 

```{r}
glimpse(texas_precinct_20)
```

Things that should be characters -- like county, precinct, candidate -- are characters (chr). Things that should be numbers (dbl) -- like votes -- are numbers.

There are some minor problems. The election_day column is a good example. It read in as a number (chr), even though there clearly are numbers in it judging from our initial inspection. Here's why: the original file has a single value in that column that is "5+".

```{r}
texas_precinct_20 |> filter(election_day == "5+")
```

Because this is just one result that's weird, we can fix it by comparing the other votes Castaneda received in Anderson to the county totals for her. The difference should be what that "5+" value should be. I've done those calculations and it turns out that 49 is the actual likely value.

We can fix that pretty easily, by changing that value to "49" using `case_when` and then using `mutate` to make the entire column numeric.

### Task 6: Fix that "election_day" value and change the "election_day" field data type

**Task** Run the following codeblock to update that single row's election day votes to 49 (".default = election_day leaves all the others unchanged), change the data type of the "election_day" field from a character (chr) to a number, and then glimpse the data, to see the change. Add a description of what the mutate code does to your reference notebook.

**Answer** After identifying the problem of '5+' in our data, we are using the mutate function to alter this error and change it to  mutate code is taking texas_precinct_20 and altering all of the '5+' to the correct numerical value. .default is used to leave everything else the same so in this case we are mutating a certain portion of the election day column but leaving the remainder how it was. In this block we are also putting as.numeric to use which changes a character column to a numeric column. 

```{r}
texas_precinct_20 <- texas_precinct_20 |>
  mutate(election_day = case_when(
    election_day == '5+' ~ '49',
    .default = election_day
  ))

texas_precinct_20 <- texas_precinct_20 |> mutate(election_day = as.numeric(election_day))

glimpse(texas_precinct_20)
```

### Task 7: Examine the franchise column for missing values.

**Task** Run the following codeblock to group by mail votes, count the number of precinct results, then sort from highest to lowest on count. How many results are there where mail is NA? What's the implication there? Answer below. 

**Answer**: There are 402345 results where mail votes is NA. The implication of this is that their is a rather large portion of the data that contains missing values for mail votes. This could affect how we analyze and interpret the data. This cause for this gap in the data may be due to an error in how mail vote data was being recorded or reported. 

```{r}

texas_precinct_20 |> 
  group_by(mail) |> 
  summarise(
    count=n()
  ) |>
  arrange(desc(count))
```

### Task 8: Install lubridate (if you haven't already)

**Task** Run the following codeblock to install the lubridate package.

```{r}
# skip this if you already have it installed.
# install.packages('lubridate')
```

### Task 9: Load lubridate

**Task** Run the following code to load the lubridate library.

```{r}
library(lubridate)
```

### Task 10: Load Yadkin voter data

**Task** Run the following codeblock to load data on registered voters in Yadkin County, North Carolina.

```{r}
yadkin_voters <- read_csv("data/yadkin_voters.csv")
```

### Task 11: Look for date gaps in data

**Task** Run the following codeblock to create a new column called "registration_month" that extracts the month and year from the "registr_dt" column. Group by the new "registration_month" column, count, and sort by "registration_month". How many registrations are there in the data for January 1900? What do you think the first 20 results suggests? Answer below.

**Answer** There are a total of 12 registrations in the data from January 1900. The first 20 results suggest that there is an error in the data. The reasoning behind my thinking stems from the fact that the registrations undergo a sudden jump from 1900 to 1933 and then to 1949 as well as how the year 1900 is an unusually early and likely inaccurate date.

```{r}
yadkin_voters |> 
  mutate(registration_month = floor_date(registr_dt, "month")) |>
  group_by(registration_month) |> 
   summarise(
    count=n()
  ) |>
  arrange(registration_month)
```

### Task 14: Check for suspicious outliers

**Task** Run the following codeblock to find the number of registered voters grouped by voter status reason, using summarise() to count. Are any of these worthy of exploration to you? Why or why not? Answer below.

**Answer** One status reason that I find particularly interesting is the "REQUEST FROM VOTER" column. There are five voters that have requested to be removed from the registered voter system... Why would anyone choose to go out of their way to make that request? I may explore this category and see if this was an error of what prompted this decision.  

```{r}

yadkin_voters |>
  group_by(voter_status_reason_desc) |> 
  summarise(count = n())
```

## Data Cleaning, Part II

### Task 1: Install janitor

**Task** Run the following codeblock to install the janitor package.

```{r}
install.packages('janitor')
```

### Task 2: Load janitor and the tidyverse

**Task** Run the following code to load the tidyverse and janitor.

```{r}
library(tidyverse)
library(janitor)
```

### Task 3: Load Arnold, Maryland demonstration data

**Task** Run the following codeblock to load a demonstration slice of the WinRed contribution data from Conowingo, Maryland. How many rows are in this demonstration data set?

**Answer** There are 14 rows in the Conowingo, Maryland demonstration data set. 

```{r}
conowingo <- read_rds("data/conowingo.rds")
```

### Task 4: Examine the data with glimpse

**Task** Run the following codeblock to glimpse the data. What data type is the "amount" field? Answer below.

**Answer** The "amount" field is a character ( <chr> ) data type. When numbers have quotes around them they are denoted as a character data type rather than a numeric data type. 

```{r}
glimpse(conowingo)
```

And let's examine the full data set.

### Task 5: Examine the data table

**Task** Run the following codeblock to examine the data. Name three problems the book chapter says exist in this data set that could prevent us from answering questions?

**Answer** There are multiple problems in this codeblock that would prevent us from accurately answering questions regarding the data. One issue would be the presence of unwanted spaces in column names. Another issue would be that some of the columns have titles that begin with a capital letter and others begin with a lowercase letter. A final issue would be that some of the column names begin with numbers which is general bad coding practice. 

```{r}
conowingo
```

### Task 6: Use clean_names()

**Task** Run the following codeblock to use the `clean_names()` function from janitor to standardize column names. How does the function change the name of the column "1_linenumber"? Answer below. Add a description of what this code does to your reference notebook.

**Answer** Janitor works effectively to clean up your column headers. One change that clean_names() implemented was that it removed any undesired or incorrect spaces and replaced them with underscores. It also ensured that all of the first letters of each column name is lowercase and removed the uppercase first letters. In order to combat the presence of column names that start with a number Janitor puts an X in front of every column name that begins with a number.  

```{r}
# cleaning function
cleaned_conowingo <- conowingo |>
  clean_names()

# display the cleaned dataset
cleaned_conowingo
```

### Task 7: Use rename()

**Task** Run the following codeblock to use the clean_names() function from janitor to standardize column names and then use rename() to change the "x1_id" column. Add a description of what this code does to your reference notebook.

**Answer** The clean_names() function takes the rather messy, confusing column name of "x1_linenumber" and make it cleaner and easier to work with. This function removed the "x1_" portion of the name to cut it down to just "linenumber". Since we only have one line number column their is no need to specify what number line number column it is in the data. 

```{r}
cleaned_conowingo <- conowingo |>
  clean_names() |> 
  rename(linenumber = x1_linenumber)

# display the cleaned dataset
cleaned_conowingo
```

### Task 8: Try summarizing the amount column

**Task** Run the following codeblock to attempt to add up the amount of all contributions. What does the error say when you run this code? What do you think the error means? Answer below. 

**Answer** The error message that I received upon running this code is, Error in `summarise()`: In argument: `total_amount = sum(amount)` Caused by error in `sum()`: invalid 'type' (character) of argument. My interpretation of this error is, as we mentioned previously, the "amount" column is stored as a character type instead of a numeric type which is preventing the sum() function from properly performing its typical arithmetic operations. 

```{r}
# cleaning function
total_conowingo <- cleaned_conowingo |>
  summarise(total_amount = sum(amount))

# display the cleaned dataset
total_conowingo


```

### Task 9: Change data type for amount

**Task** Run the following codeblock to attempt to change the datatype for the amount field to a number. What is the new data type (three letter code) for amount? Answer below. 

**Answer** After being altered, the new datatype for the "amount" field is numeric (<dbl>). This fix allows the code to run the sum() function without error. 

```{r}
# cleaning function
cleaned_conowingo <- conowingo |>
  clean_names() |> 
  rename(linenumber = x1_linenumber) |> 
  mutate(amount = as.numeric(amount))
  

# display the cleaned dataset
cleaned_conowingo

```

### Task 10: Try again to summarize the amount column

**Task** Run the following codeblock to add up the amount of all contributions in this data. What is the total? Answer below. 

**Answer** Their are 226 total contributions in this data. 

```{r}
# cleaning function
total_conowingo <- cleaned_conowingo |>
  summarise(total_amount = sum(amount))

# display the cleaned dataset
total_conowingo


```

### Task 11: Check for duplicate rows

**Task** Run the following codeblock to check for duplicate rows using get_dupes(). How many are there? What is the donor name? Answer below. 

**Answer** The get_dupes() function allows for the identification of one set (2 total) duplicate rows present in the data. The donor name of this duplicate is Derrick Hamilton. 

```{r}
cleaned_conowingo |> 
  get_dupes()
```

### Task 12: Check for duplicate rows

**Task** Run the following codeblock to use distinct() to get rid of duplicate rows. How many rows does the new dataframe have? Answer below. Add a description of what this code does to your reference notebook.

**Answer** The new dataframe has a total of 13 new rows. The distinct() function works to remove dupliate rows from a data frame or tibble. In this case it is cleaning the data and making sure that only unique rows based on specified columns.

```{r}
# cleaning function
cleaned_conowingo <- conowingo |>
  clean_names() |> 
  rename(linenumber = x1_linenumber) |> 
  mutate(amount = as.numeric(amount)) |> 
  distinct()
  

# display the cleaned dataset
cleaned_conowingo

```

### Task 13: Clean up ZIP code

**Task** Run the following codeblock to use str_sub() to convert the ZIP codes that have nine digits to five digits, standardizing the field. Look at the difference in the result - what changed? 

**Answer** Prior to using the str_sub() function the data displayed a combination of nine digit and five digit ZIP codes. After implimenting this cleaning function we are converting the data to display only five digit ZIP codes. This change makes the data far more clean and concise. 

```{r}
# cleaning function
cleaned_conowingo <- conowingo |>
  clean_names() |> 
  rename(linenumber = x1_linenumber) |> 
  mutate(amount = as.numeric(amount)) |> 
  distinct() |>
  mutate(zip = str_sub(zip, start=1L, end=5L))
  

# display the cleaned dataset
cleaned_conowingo

```

### Task 14: Clean up city field

**Task** Run the following codeblock to use str_tot_title() to standarize capitalization in the "city" field. How many mispellings of Conowingo remain after running this code? Answer below. Add a description of what this code does to your reference notebook.

**Answer** After running str_tot_title() to standardize capitalization in the "city" field there are still 2 remaining misspellings of Conowingo remaining in the code. These misspellings are "Conowing" and "Conowingoo". The function clean_names() standardizes a column, in this case the title column, to be lowercase and replaces all of the spaces with underscores. 

```{r}
# cleaning function
cleaned_conowingo <- conowingo |>
  clean_names() |> 
  rename(linenumber = x1_linenumber) |> 
  mutate(amount = as.numeric(amount)) |> 
  distinct() |>
  mutate(zip = str_sub(zip, start=1L, end=5L)) |>
  mutate(city = str_to_title(city))
  

# display the cleaned dataset
cleaned_conowingo

```

### Task 15: Clean up city field more with case_when()

**Task** Run the following codeblock to use case_when() to fix misspellings of Conowingo in the "city" field. How many mispellings of Conowingo remain after running this code? Answer below. 

**Answer** By implementing the case_when() function we are effectively eliminating one of the two remaining misspellings of Conowingo in the "city" field. Their is only one remaining misspelling and it is "Conowingoo". 

```{r}
# cleaning function
cleaned_conowingo <- conowingo |>
  clean_names() |> 
  rename(linenumber = x1_linenumber) |> 
  mutate(amount = as.numeric(amount)) |> 
  distinct() |>
  mutate(zip = str_sub(zip, start=1L, end=5L)) |>
  mutate(city = str_to_title(city)) |>
  mutate(city = case_when(
    city == "Conowing" ~ "Conowingo",
    TRUE ~ city
  ))

# display the cleaned dataset
cleaned_conowingo

```

### Task 16: Clean up city field more with case_when()

**Task** Run the following codeblock to use case_when() to fix misspellings of Conowingo in the "city" field using both the exact match method and the str_detect() method. How many mispellings of Conowingo remain after running this code? Answer below. Add a description of what this code does to your reference notebook. 

**Answer** There are no more remaining misspellings of Conowingo after using both case_when() and the str_detect() method. The purpose of this code is to target and correct specific misspelling sin the "city" field. In this case it identified the misspellings of "Conowing" and "Conowingoo" and changed them to their correct form of "Conowingo". 

```{r}
# cleaning function
cleaned_conowingo <- conowingo |>
  clean_names() |> 
  rename(linenumber = x1_linenumber) |> 
  mutate(amount = as.numeric(amount)) |> 
  distinct() |>
  mutate(zip = str_sub(zip, start=1L, end=5L)) |>
  mutate(city = str_to_title(city)) |>
  mutate(city = case_when(
    str_detect(city,"^Conowing") ~ "Conowingo",
    TRUE ~ city
  ))
  

# display the cleaned dataset
cleaned_conowingo

```
